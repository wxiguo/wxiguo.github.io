<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2Fposts%2F0.html</url>
    <content type="text"><![CDATA[Docker 与 MUMU模拟器 Windows 10 环境切换使用Docker 在 Windows 10 环境使用需要开启 Hyper-v 虚拟化功能，与市场大部分 Android 模拟器依赖的 HAXM 冲突。可根据实际使用情况开启或关闭 Hyper-v 功能。 Hyper-v 开启与关闭以管理员运行 CMD 执行以下命令： 开启命令 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All 关闭命令 1Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V]]></content>
  </entry>
  <entry>
    <title><![CDATA[Apache kafka（三）Kafka与Spring整合]]></title>
    <url>%2Fposts%2Faa51fcd.html</url>
    <content type="text"><![CDATA[Kafka与Spring整合maven依赖： 123456789101112... org.springframework.boot spring-boot-starter-web 2.1.6.RELEASE org.springframework.kafka spring-kafka 2.2.7.RELEASE ... 生产者基于配置application-Kafka.xml 1234567891011121314151617181920212223 ProducerController.java 123456789101112@RestControllerpublic class ProducerController { @Autowired KafkaTemplate kafkaTemplate; @GetMapping("/test") public String doTest() { kafkaTemplate.send("my-topic", "Hello World"); return "success"; }} 基于注解application.properties 12345# Kafka configsspring.kafka.bootstrap-servers=localhost:9092spring.kafka.client-id=KafkaProducerspring.kafka.acks=allapp.topic.foo=my-topic SenderConfig.java 1234567891011121314151617181920212223242526272829303132@Configuration@EnableKafkapublic class SenderConfig { @Value("${spring.kafka.bootstrap-servers}") private String bootstrapServers; @Value("${spring.kafka.client-id}") private String clientId; @Value("${spring.kafka.acks}") private String acks; @Bean public Map producerConfigs() { Map props = new HashMap(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); props.put(ProducerConfig.CLIENT_ID_CONFIG, clientId); props.put(ProducerConfig.ACKS_CONFIG, acks); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return props; } @Bean public ProducerFactory producerFactory() { return new DefaultKafkaProducerFactory(producerConfigs()); } @Bean public KafkaTemplate kafkaTemplate() { return new KafkaTemplate(producerFactory()); }} Sender.java 123456789101112131415@RestControllerpublic class Sender { @Autowired private KafkaTemplate kafkaTemplate; @Value("${app.topic.foo}") private String topic; @GetMapping("test") public String send() { kafkaTemplate.send(topic, "topic_key", "Hello Word!"); return "success"; }} 消费者基于配置application-Kafka.xml 123456789101112131415161718192021222324252627282930313233343536 RegistryServers.java 12345678public class RegistryServers implements MessageListener { @Override public void onMessage(ConsumerRecord record) { System.out.println("接收到消息："); System.out.println(record.value()); }} 基于注解application.properties 1234567# Kafka configsspring.kafka.bootstrap-servers=localhost:9092spring.kafka.group-id=KafkaConsumerspring.kafka.enable-auto-commit=truespring.kafka.auto-commit-interval-ms=1000spring.kafka.auto-offset-reset=earliestapp.topic.foo=my-topic ReceiverConfig.java 12345678910111213141516171819202122232425262728293031323334353637383940@Configuration@EnableKafkapublic class ReceiverConfig { @Value("${spring.kafka.bootstrap-servers}") private String bootstrapServers; @Value("${spring.kafka.group-id}") private String groupId; @Value("${spring.kafka.enable-auto-commit}") private String enableAutoCommit; @Value("${spring.kafka.auto-commit-interval-ms}") private String autoCommitIntervalMs; @Value("${spring.kafka.auto-offset-reset}") private String autoOffsetReset; @Bean public Map consumerConfigs() { Map props = new HashMap(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, enableAutoCommit); props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, autoCommitIntervalMs); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, autoOffsetReset); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); return props; } @Bean public ConsumerFactory consumerFactory() { return new DefaultKafkaConsumerFactory(consumerConfigs()); } @Bean public KafkaListenerContainerFactory kafkaListenerContainerFactory() { ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory(); factory.setConsumerFactory(consumerFactory()); return factory; }} Receiver.java 12345678@Servicepublic class Receiver { @KafkaListener(topics = "${app.topic.foo}") public void listen(ConsumerRecord record) { System.out.println(String.format("key: %s and value: %s", record.key(), record.value())); }} 相关参考 Spring for Apache Kafka]]></content>
      <categories>
        <category>Apache Kafka</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>Kafka</tag>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache kafka（二）简单生产者、消费者组示例]]></title>
    <url>%2Fposts%2F970f1b95.html</url>
    <content type="text"><![CDATA[APISKafka包括五个核心apis： Producer API：允许应用程序将数据流发送到Kafka集群中的主题。 Consumer API：允许应用程序从Kafka集群中的主题读取数据流。 Streams API：允许将输入主题的数据流转换为输出主题。 Connect API：允许实现从某些源系统或应用程序不断拉入Kafka或从Kafka推送到某个接收器系统或应用程序的连接器。 AdminClient API：允许管理和检查主题，代理和其他Kafka对象。 Kafka通过独立于语言的协议公开其所有功能，该协议具有许多编程语言的客户端。 简单生产者Producer API允许应用程序将数据流发送到Kafka集群中的主题。 maven依赖： 12345 org.apache.kafka kafka-clients 2.3.0 生产者是线程安全的，跨线程共享单个生成器实例通常比拥有多个实例更快。 示例12345678910111213public static void main(String[] args) { Properties props = new Properties(); props.put("bootstrap.servers","localhost:9092"); props.put("acks","all"); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); Producer producer = new KafkaProducer(props); for (int i = 0; i < 100; i++){ producer.send(new ProducerRecord("my-topic", Integer.toString(i), Integer.toString(i))); } producer.close();} 生产者包含一个缓存控制池，用于保存尚未传输到服务器的记录，以及一个后台 I/O 线程，负责将这些记录转换为请求并将它们传输到集群。 没有在使用后关闭生产者将泄漏这些资源。 send() 方法是异步的。 调用时，它会将记录添加到待处理记录发送的缓冲区中并立即返回。 这允许生产者将各个记录一起批处理以提高效率。 acks 配置控制认为请求完成的标准。 我们指定的“all”设置将导致完全提交记录时阻塞，这是最慢但最耐用的设置。 生产者可选配置 No. 配置设置 配置说明 1 client.id 标识生产者应用程序 2 producer.type 同步或异步 3 acks acks 配置表示 producer 发送消息到 broker 上以后的确认值。0：表示 producer 不需要等待 broker 的消息确认。这个选项时延最小但同时风险最大（因为当 server 宕机时，数据将会丢失） 。1：表示 producer 只需要获得 kafka 集群中的 leader 节点确认即可，这个选择时延较小同时确保了 leader 节点确认接收成功。all(-1)：需要 ISR 中所有的 Replica 给予接收确认，速度最慢，安全性最高，但是由于 ISR 可能会缩小到仅包含一个 Replica，所以设置参数为 all 并不能一定避免数据丢失。 4 retries 如果生产者请求失败，则会自动重试具体值。 5 bootstrap.servers 经纪人的引导列表。 6 linger.ms 如果要减少请求数，可以将linger.ms设置为大于某值的值。Producer 默认会把两次发送时间间隔内收集到的所有 Requests 进行一次聚合然后再发送，以此提高吞吐量，而 linger.ms 就是为每次发送到 broker 的请求增加一些 delay，以此来聚合更多的 Message 请求。 7 key.serializer 串行器接口的关键。 8 value.serializer 串行器接口的值。 9 batch.size 缓冲区大小。生产者发送多个消息到 broker 上的同一个分区时，为了减少网络请求带来的性能开销，通过批量的方式来提交消息，可以通过这个参数来控制批量提交的字节数大小，默认大小是 16384byte,也就是 16kb，意味着当一批消息大小达到指定的 batch.size 的时候会统一发送。 10 buffer.memory 控制生产者可用于缓冲的总内存量。 11 max.request.size 设置请求的数据的最大字节数，为了防止发生较大的数据包影响到吞吐量，默认值为 1MB。 ProducerRecord 类参数 String topic - 创建主题以分配记录 K key - 键记录 V value - 记录内容 单一事务示例12345678910111213141516171819202122public static void main(String[] args) { Properties props = new Properties(); props.put("bootstrap.servers", "localhost:9092"); props.put("transactional.id", "my-transactional-id"); Producer producer = new KafkaProducer(props, new StringSerializer(), new StringSerializer()); producer.initTransactions(); try { producer.beginTransaction(); for (int i = 0; i < 100; i++) producer.send(new ProducerRecord("my-topic", Integer.toString(i), Integer.toString(i))); producer.commitTransaction(); } catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) { // 异常，关闭生产者 producer.close(); } catch (KafkaException e) { // 异常，重试 producer.abortTransaction(); } producer.close();} 每个生产者只能有一个开放交易。 在 beginTransaction() 和 commitTransaction() 调用之间发送的所有消息都将是单个事务的一部分。 指定 transactional.id 时，生产者发送的所有消息都必须是事务的一部分。 消费者组Consumer API允许应用程序从Kafka集群中的主题读取数据流。 maven依赖： 12345 org.apache.kafka kafka-clients 2.3.0 Kafka消费者不是线程安全的。 所有网络 I/O 都发生在进行调用的应用程序的线程中。此规则的唯一例外是wakeup()，它可以安全地从外部线程用于中断活动操作。 在这种情况下，将从操作的线程阻塞中抛出WakeupException。 这可以用于从另一个线程关闭使用者。 示例自动抵消提交1234567891011121314151617public static void main(String[] args) { Properties props = new Properties(); props.put("bootstrap.servers", "localhost:9092"); props.setProperty("group.id", "test"); props.setProperty("enable.auto.commit", "true"); props.setProperty("auto.commit.interval.ms", "1000"); props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); KafkaConsumer consumer = new KafkaConsumer(props); consumer.subscribe(Arrays.asList("my-topic", "foo", "bar")); while (true) { ConsumerRecords records = consumer.poll(Duration.ofMinutes(100)); for (ConsumerRecord record : records) { System.out.println(String.format("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value())); } }} 手动偏移控制12345678910111213141516171819202122232425public static void main(String[] args) { Properties props = new Properties(); props.setProperty("bootstrap.servers", "localhost:9092"); props.setProperty("group.id", "test"); props.setProperty("enable.auto.commit", "false"); props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); KafkaConsumer consumer = new KafkaConsumer(props); consumer.subscribe(Arrays.asList("my-topic", "foo", "bar")); final int minBatchSize = 200; List buffer = new ArrayList(); while (true) { ConsumerRecords records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecord record : records) { buffer.add(record); } if (buffer.size() >= minBatchSize) { // 业务处理// insertIntoDb(buffer); System.out.println(buffer.toString()); consumer.commitSync(); buffer.clear(); } }} 上面的示例使用commitSync将所有已接收的记录标记为已提交。 在某些情况下，您可能希望通过明确指定偏移量来更好地控制已提交的记录。 在下面的示例中，我们在完成处理每个分区中的记录后提交偏移量。 12345678910111213141516171819202122232425public static void main(String[] args) { Properties props = new Properties(); props.setProperty("bootstrap.servers", "localhost:9092"); props.setProperty("group.id", "test"); props.setProperty("enable.auto.commit", "false"); props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); KafkaConsumer consumer = new KafkaConsumer(props); consumer.subscribe(Arrays.asList("my-topic", "foo", "bar")); try { while (true) { ConsumerRecords records = consumer.poll(Duration.ofMillis(Long.MAX_VALUE)); for (TopicPartition partition : records.partitions()) { List partitionRecords = records.records(partition); for (ConsumerRecord record : partitionRecords) { System.out.println(record.offset() + ": " + record.value()); } long lastOffset = partitionRecords.get(partitionRecords.size() - 1).offset(); consumer.commitSync(Collections.singletonMap(partition, new OffsetAndMetadata(lastOffset + 1))); } } } finally { consumer.close(); }} 注意：提交的偏移量应始终是应用程序将读取的下一条消息的偏移量。 因此，在调用commitSync（偏移量）时，您应该在最后处理的消息的偏移量中添加一个。 消费者配置 No. 配置设置 配置说明 1 group.id 消费组id。不同消费组都可以获取到生产内容，同一消费组内只有一个 consumer 可以消费。 2 enable.auto.commit 消费者消费消息以后自动提交，只有当消息提交以后，该消息才不会被再次接收到，还可以配合 auto.commit.interval.ms 控制自动提交的频率。当然，我们也可以通过 consumer.commitSync()的方式实现手动提交。 3 auto.offset.reset auto.offset.reset=latest 情况下，新的消费者将会从其他消费者最后消费的offset 处开始消费 Topic 下的消息。auto.offset.reset= earliest 情况下，新的消费者会从该 topic 最早的消息开始消费。auto.offset.reset=none 情况下，新的消费者加入以后，由于之前不存在offset，则会直接抛出异常。 4 max.poll.records 此设置限制每次调用 poll 返回的消息数，这样可以更容易的预测每次 poll 间隔要处理的最大值。通过调整此值，可以减少 poll 间隔。 相关参考 Kafka官网 Kafka 2.3 Javadoc W3Cschool Apache Kafka 教程]]></content>
      <categories>
        <category>Apache Kafka</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>Kafka</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache kafka（一）简介及入门]]></title>
    <url>%2Fposts%2Fbfbb468b.html</url>
    <content type="text"><![CDATA[简介Kafka是一个分布式流处理平台。Kafka于2009年源自Linkedin，随后于2011年初开源，并于2012年10月23由Apache Incubator孵化出站。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。 流处理平台三个关键功能 发布和订阅记录流，类似于消息队列或企业消息传递系统。 以容错持久的方式存储记录流。 处理记录发生的流。 Kafka通常用于两大类应用 构建可在系统或应用程序之间可靠获取数据的实时流数据管道 构建实时流应用程序，用于转换或相应数据流 几个基本概念 Kafka作为一个集群运行在一台或多台可以跨越多个数据中心的服务器上。 Kafka集群在称为主题的类别中存储记录流。 每个记录由一个键，一个值和一个时间戳组成。 Kafka 的架构Kafka架构的主要术语包括Topic、Record和Broker。Topic由Record组成，Record持有不同的信息，而Broker则负责复制消息。 四个核心 API 生产者API：支持应用发布Record流。 消费者API：支持应用程序订阅Topic和处理Record流。 Stream API：将输入流转换为输出流，并产生结果。 Connector API：执行可重用的生产者和消费者API，可将Topic链接到现有应用程序。 安装及使用 基于Unix平台上使用bin/，脚本扩展名为.sh 。 WIndows平台上使用bin\windows\，并且脚本扩展名为.bat。 以下命令均在Windows平台执行。 第1步：下载代码下载 2.3.0版本并解压它。Windows平台直接解压。 1>cd kafka_2.12-2.3.0 第2步：启动服务器Kafka使用ZooKeeper，首先启动ZooKeeper服务器，使用Kafka打包在一起的便捷脚本使用单节点的ZooKeeper实例。 1>bin\windows\zookeeper-server-start.bat config\zookeeper.properties ZooKeeper成功启动，并绑定到端口2181。该端口是ZooKeeper的默认端口，可以在config\zookeeper.properties中修改clientPort来修改监听端口。 启动Kafka服务器： 1>bin\windows\kafka-server-start.bat config\server.properties windows环境下启动命令中的配置文件路径 .properties 需要 ..\..\xx.properties。 第3步：创建一个主题创建一个名为“HelloWord”的主题： 1>bin\windows\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic HelloWord 通过运行list topic命令查询创建的主题： 1>bin\windows\kafka-topics.bat --list --zookeeper localhost:2181 或者也可以将代理配置设置为发布不存在的主题是自动创建主题。 第4步：启动一个生产者并发送消息123>bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic HelloWordThis is a messagehello,my is producer 第5步：启动一个消费者并接收消息123>bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic HelloWord --from-beginningThis is a messagehello,my is producer Kafka 集群配置 配置 Kafka 的 Zookeeper 地址 zookeeper.connect 。Zookeeper集群可通过 , 分开。 192.168.1.100 和 192.168.1.101 Zookeeper 配置： 1234567891011############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=192.168.1.200:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000 修改 broker.id ， broker.id 在集群中必须是唯一的。 192.168.1.100 配置 ： 12# The id of the broker. This must be set to a unique integer for each broker.broker.id=0 192.168.1.101 配置： 12# The id of the broker. This must be set to a unique integer for each broker.broker.id=1 listeners 写入本机IP，集群中完成节点间通讯使用。 192.168.1.100 配置： 1234567# The address the socket server listens on. It will get the value returned from # java.net.InetAddress.getCanonicalHostName() if not configured.# FORMAT:# listeners = listener_name://host_name:port# EXAMPLE:# listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://192.168.1.100:9092 192.168.1.101 配置： 1234567# The address the socket server listens on. It will get the value returned from # java.net.InetAddress.getCanonicalHostName() if not configured.# FORMAT:# listeners = listener_name://host_name:port# EXAMPLE:# listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://192.168.1.101:9092 查询 Kafka 集群节点部署情况。 123456>zookeeper-shell.sh 192.168.1.200:2181...>ls /brokers/ids[0, 1]>get /controller... ls /brokers/ids 查询注册了 zookeeper 节点的 broker.id 。 get /controller 查询 leader，master 节点。 异常及处理 启动Kafka服务，命令窗口提示错误： 12>bin\windows\kafka-server-start.bat config\server.properties错误: 找不到或无法加载主类 Files\Java\jdk1.7.0_75\lib\dt.jar;C:\Program 网上查找解决办法，修改kafka-server-satrt.bat： 123set COMMAND=%JAVA% %KAFKA_HEAP_OPTS% %KAFKA_JVM_PERFORMANCE_OPTS% %KAFKA_JMX_OPTS% %KAFKA_LOG4J_OPTS% -cp %CLASSPATH% %KAFKA_OPTS% %*修改为：set COMMAND=%JAVA% %KAFKA_HEAP_OPTS% %KAFKA_JVM_PERFORMANCE_OPTS% %KAFKA_JMX_OPTS% %KAFKA_LOG4J_OPTS% -cp "%CLASSPATH%" %KAFKA_OPTS% %* 给上述代码段的%CLASSPATH%添加双引号""。 启动生产者时Kafka报错： 12>bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic HelloWordWARN [Consumer clientId=consumer-1, groupId=console-consumer-950] Connection to node -1 could not be established. Broker may not be available. 因为配置文件conf\server.properties没有启用PLAINTEXT，修改配置文件： 12#listeners=PLAINTEXT://:9092listeners=PLAINTEXT://localhost:9092 相关参考 Kafka官网 Kafka维基百科 [Kafka][错误: 找不到或无法加载主类 Files\Java\jdk1.8.0_101\lib\dt.jar;C:\Program] WARN [Consumer clientId=consumer-1, groupId=console-consumer-950] Connection to node -1 could not be The Log: What every software engineer should know about real-time data’s unifying abstraction]]></content>
      <categories>
        <category>Apache Kafka</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梅林固件编写cru脚本清理高速缓存重启路由]]></title>
    <url>%2Fposts%2Fe616b06d.html</url>
    <content type="text"><![CDATA[R6300V2_梅林RT-AC68U 定时清理高速缓存、每天重启路由刷梅林有几个月了，第一次问题出是在连续使用30多天后，发现手机能连接路由器但不能上网，不能访问路由器管理页面。连接不上网络的问题需要手动重启路由器，很麻烦，尤其是人不在家想连接家里的NAS和摄像头没办法远程重启路由器。出门在外，顺子(喵)独自在家不放心。本来想有什么网络监控设备，找了一圈发现可以用路由器脚本定时检测，自动重启解决。暂时没有时间整理编写定时检测监本，先用定时清理高速缓存和每天重启脚本用一段时间看看。 使用WinSCP登录路由器配置路由器开启SSH链接：登录路由器管理界面–>系统管理–>系统设置–>SSH Daemon–>Enable SSH选择开启SSH访问。 使用工具WinSCP选择SCP访问，端口配置与SSH配置相同，使用路由器用户名和密码登录。 编写路由器监控脚本 下面新建sh文件全部使用utf-8编码，设置文件0755权限 使用WinSCP登录路由器后，进入/jffs/scripts/目录，使用内置编辑器新建清除缓存文件clean.sh，内容如下： 123#!/bin/shsyncecho 3 > /proc/sys/vm/drop_caches 新建定时文件cru.sh，内容如下： 123#!/bin/shcru a clean "0 */4 * * * /bin/sh /jffs/scripts/clean.sh"cru a reboot "0 4 * * * /sbin/reboot" 上面代码的意思是： 每4小时清理一次缓存。 每天临晨4点重启路由器。 按下图在路由器管理界面Tools-Script里将cru.sh添加到开机启动： 然后重启机器，或者断开WAN后重连。 配置完成后为安全性考虑，请关闭SSH访问链接。 修改NTP服务器梅林自带NTP服务器地址pool.ntp.org在国内访问并不是很好，经常会有访问不了的情况导致时间不同步，重启后无法链接WAN的问题，修改NTP服务器地址为time.pool.aliyun.com，修改后半个多月了，没有发生重启后无法WAN上网的问题。 相关参考 梅林系统手动编写cru定时脚本 自动重启/释放内存 OpenWRT路由器中监控网络服务并重启的脚本 梅林重起后一定几率无法访问Internet，我的解决办法。]]></content>
      <categories>
        <category>Merlin</category>
      </categories>
      <tags>
        <tag>Merlin</tag>
        <tag>cru</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaMail发送邮件]]></title>
    <url>%2Fposts%2Fa5bad747.html</url>
    <content type="text"><![CDATA[简介JavaMail是Sun公司提供给开发人员在程序中处理Email的API，JavaMail未加入到JDK中，需要自己下载使用。 jar包下载配置maven信息： 1234567 com.sun.mail javax.mail 1.6.1 Java代码段123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158import java.io.File;import java.util.Date;import java.util.Properties;import javax.activation.DataHandler;import javax.activation.DataSource;import javax.activation.FileDataSource;import javax.mail.Authenticator;import javax.mail.BodyPart;import javax.mail.Message.RecipientType;import javax.mail.Multipart;import javax.mail.PasswordAuthentication;import javax.mail.Session;import javax.mail.Transport;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeBodyPart;import javax.mail.internet.MimeMessage;import javax.mail.internet.MimeMultipart;import javax.mail.internet.MimeUtility;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import cn.com.****.basis.utils.Constants;import com.sun.mail.util.MailSSLSocketFactory;/** * @author wxg * @version 创建时间：2018年4月4日 上午10:04:18 * @explain */public class JavaMailUtils { private static final Logger log = LoggerFactory.getLogger(JavaMailUtils.class); private final static String OUTPUT = Constants.emailProperties.jsp_getValue("output"); private final static String MAILSERVER = Constants.emailProperties.jsp_getValue("mailServer"); private final static String LOGINACCOUNT = Constants.emailProperties.jsp_getValue("loginAccount"); private final static String LOGINAUTHCODE = Constants.emailProperties.jsp_getValue("loginAuthCode"); private final static String Sender = Constants.emailProperties.jsp_getValue("sender"); private final static String[] RECIPIENTS = Constants.emailProperties.jsp_getValue("recipient").split(","); private final static String EMAILCONTENTTYPE = "text/html;charset=utf-8"; /** * * @Title: sendEmail * @Description: 邮件发送工具 * @param: @param mailServer 邮件服务器的主机名:如 "smtp.**.com" * @param: @param loginAccount 登录邮箱的账号:如 "******@***.com" * @param: @param loginAuthCode 登录邮箱，账号设置那里"生成授权码" * @param: @param sender 发件人 * @param: @param recipients 收件人:支持群发 * @param: @param emailSubject 邮件的主题 * @param: @param emailContent 邮件的内容 * @param: @param emailContentType 邮件内容的类型,支持纯文本:"text/plain;charset=utf-8";带有Html格式的内容:"text/html;charset=utf-8"; * @param: @param attachment 邮件附件，目录下所有文件 * @param: @return true or false * @return: boolean * @throws */ public static boolean sendEmail(String mailServer, final String loginAccount, final String loginAuthCode, String sender, String[] recipients, String emailSubject, String emailContent, String emailContentType, File[] attachment) { boolean res = false; try{ // 跟smtp服务器建立连接 Properties properties = new Properties(); // 设置邮件服务器主机名 properties.setProperty("mail.smtp.host", mailServer); // 发送服务器身份验证，采用用户名和密码方式 properties.setProperty("mail.smtp.auth", "true"); // 发送邮件协议名称 properties.setProperty("mail.transport.protocol", "smtp"); // 开启SSL加密 MailSSLSocketFactory mailSSLSocketFactory = new MailSSLSocketFactory(); mailSSLSocketFactory.setTrustAllHosts(true); properties.put("mail.smtp.ssl.enable", "true"); properties.put("mail.smtp.ssl.socketFactory", mailSSLSocketFactory); // 创建session Session session = Session.getDefaultInstance(properties, new Authenticator(){ protected PasswordAuthentication getPasswordAuthentication(){ PasswordAuthentication passwordAuth = new PasswordAuthentication(loginAccount, loginAuthCode); return passwordAuth; } }); // 设置打开调试状态 session.setDebug(false); // 创建一封邮件 MimeMessage mimeMessage = new MimeMessage(session); // 发件人 mimeMessage.setFrom(new InternetAddress(sender)); // 收件人 InternetAddress[] recipientsEmail = new InternetAddress[recipients.length]; for(int i = 0;i < recipients.length;i++){ recipientsEmail[i] = new InternetAddress(recipients[i]); } mimeMessage.setRecipients(RecipientType.TO, recipientsEmail); // 抄送人// mimeMessage.setRecipients(RecipientType.CC, recipientsEmail); // 设置多个密送地址// mimeMessage.setRecipients(RecipientType.BCC, recipientsEmail); // 发送日期 mimeMessage.setSentDate(new Date()); // 设置邮件标题 mimeMessage.setSubject(emailSubject); // 添加正文和附件 Multipart multipart = new MimeMultipart(); // 添加邮件正文 BodyPart contentPart = new MimeBodyPart(); contentPart.setContent(emailContent, emailContentType); multipart.addBodyPart(contentPart); // 设置附件 BodyPart attachmentBodyPart = null; // 添加附件的内容 if (null != attachment && attachment.length != 0) { for (File file : attachment) { attachmentBodyPart = new MimeBodyPart(); DataSource source = new FileDataSource(file); attachmentBodyPart.setDataHandler(new DataHandler(source)); // MimeUtility.encodeWord可以避免文件名乱码 attachmentBodyPart.setFileName(MimeUtility.encodeWord(file.getName())); multipart.addBodyPart(attachmentBodyPart); } } // 将multipart对象放到message中 mimeMessage.setContent(multipart); // 设置邮件内容// mimeMessage.setContent(emailContent, emailContentType); // 发送邮件 Transport.send(mimeMessage); log.error("邮件发送成功"); res = true; }catch(Exception e){ log.error("邮件发送失败: " + e.getMessage(), e); res = false; } return res; } /** * * @Title: sendEmail * @Description: 发送普通邮件 * @param: @param emailSubject 主题 * @param: @param emailContent 内容 * @param: @return * @return: boolean * @throws */ public static boolean sendEmail(String emailSubject, String emailContent){ if(OUTPUT.equals("true")){// File file = new File("D:\\中文cs");// File[] files = file.listFiles(); return sendEmail(MAILSERVER, LOGINACCOUNT, LOGINAUTHCODE, Sender, RECIPIENTS, emailSubject, emailContent, EMAILCONTENTTYPE, null); } return false; } 异常处理需要注意的是，在本机junit测试配置是正常的，但是启动服务后发送邮件程序异常，日志如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455java.lang.UnsupportedOperationException: Method not yet implemented at javax.mail.internet.MimeMessage.(MimeMessage.java:89) ~[geronimo-spec-javamail-1.3.1-rc3.jar:1.3.1-rc3] at cn.com.****.basis.utils.JavaMailUtils.sendEmail(JavaMailUtils.java:93) [classes/:na] at cn.com.****.basis.utils.JavaMailUtils.sendEmail(JavaMailUtils.java:159) [classes/:na] at cn.com.****.********.controller.CreateXmlData.createXmlAll(CreateXmlData.java:174) [classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_75] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_75] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_75] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_75] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:622) [servlet-api.jar:na] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842) [spring-webmvc-4.1.5.RELEASE.jar:4.1.5.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [servlet-api.jar:na] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:292) [catalina.jar:8.0.35] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) [catalina.jar:8.0.35] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-websocket.jar:8.0.35] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) [catalina.jar:8.0.35] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) [catalina.jar:8.0.35] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) [catalina.jar:8.0.35] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) [catalina.jar:8.0.35] at org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) [spring-orm-4.1.6.RELEASE.jar:4.1.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) [catalina.jar:8.0.35] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) [catalina.jar:8.0.35] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.1.5.RELEASE.jar:4.1.5.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) [catalina.jar:8.0.35] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) [catalina.jar:8.0.35] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212) [catalina.jar:8.0.35] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [catalina.jar:8.0.35] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [catalina.jar:8.0.35] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:141) [catalina.jar:8.0.35] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [catalina.jar:8.0.35] at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616) [catalina.jar:8.0.35] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [catalina.jar:8.0.35] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:528) [catalina.jar:8.0.35] at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1099) [tomcat-coyote.jar:8.0.35] at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:672) [tomcat-coyote.jar:8.0.35] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1520) [tomcat-coyote.jar:8.0.35] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1476) [tomcat-coyote.jar:8.0.35] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_75] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_75] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-util.jar:8.0.35] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_75] 经过查询是jar冲突导致的，定位到geronimo-spec-javamail.jar问题，通过maven的exclusions标签注释掉该jar包，问题解决。配置如下： 12345678910111213141516 com.cloudhopper.proxool proxool 0.9.1 geronimo-spec geronimo-spec-javamail geronimo-spec geronimo-spec-jms]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JavaUtils</tag>
        <tag>邮件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Travis自动部署Hexo]]></title>
    <url>%2Fposts%2Fe2434ddb.html</url>
    <content type="text"><![CDATA[Travis配置GItHub创建Access Token登录GItHub–>GitHub用户头像–>Setting–>Developer settings–>Personal access tokens–>Generate new token 勾选repo及user:email点击创建。生成的token只显示一次，所以需要先保存起来后面会用到。 Travis CI配置 配置Travis公共仓库服务：travis-ci.org，配置Travis私有化仓库服务：travis-ci.com 这里我们使用公共仓库服务travis-ci.org 打开Travis CI网站，使用GItHub账号登录，点击Sync account会显示GitHub项目列表。选择博客项目开启Travis支持。 点击项目找到More options中的Setting开启Build only if .travis.yml is present和Build pushed branches。 在Environment Variables创建环境变量TravisCIToken值为在GItHub创建的Access Token的token值。不要勾选Display value in build log，否则会在日志文件中暴露 token 信息。 创建.travis.yml文件 注意yml文件中不能使用tab进行缩进，使用空格缩进，:后有一个空格。 Hexo根目录blog文件夹内创建.travis.yml： 1234567891011121314151617181920212223anguage: node_jsnode_js: stablecache: apt: true directories: - node_modulesbefore_install: - export TZ='Asia/Shanghai' - npm install hexo-cli -g - chmod +x ./publish-to-gh-pages.shinstall: - npm installscript: - hexo clean - hexo gafter_script: - ./publish-to-gh-pages.shbranches: only: - hexoenv: global: - GH_REF: github.com//.github.io.git Hexo根目录blog文件夹内创建publish-to-gh-pages.sh： 123456789101112131415#!/bin/bashset -ev# get clone mastergit clone https://${GH_REF} .deploy_gitcd .deploy_gitgit checkout mastercd ../mv .deploy_git/.git/ ./public/cd ./publicgit config user.name ""git config user.email ""# add commit timestampgit add .git commit -m "Travis CI Auto Builder at `date +"%Y-%m-%d %H:%M"`"git push --force --quiet "https://${TravisCIToken}@${GH_REF}" master:master 自动部署 打开Git Bash 以下操作全部在Hexo根目录blog文件夹内执行 创建远程分支 1$ git checkout -b hexo 初始化本地仓库： 删除原来部署时产生的.git文件夹（隐藏文件夹） 1$ git init 关联远程仓库 1$ git remote add origin git@github.com:/.github.io.git 推送仓库 123$ git add . # 添加文件$ git commit -m "first import" # 编写注释$ git push -u origin hexo # 推送至远程仓库hexo分支 推送成功后可以在travis-ci.org后台查看自动部署情况。 相关参考 手把手教从零开始在GitHub上使用Hexo搭建博客教程(三)-使用Travis自动部署Hexo(1) 手把手教从零开始在GitHub上使用Hexo搭建博客教程(四)-使用Travis自动部署Hexo(2) 使用Travis CI自动部署Hexo博客]]></content>
      <categories>
        <category>Hexo博客</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Travis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客搭建]]></title>
    <url>%2Fposts%2Fb8f4bd70.html</url>
    <content type="text"><![CDATA[安装 Git 已安装过的用户略过 windows：下载并安装 Git 安装 Node.js windows：下载并安装 Node.js GitHub仓库配置创建仓库 GitHub仓库名称必须是 .github.io 配置SSH 打开GitBash终端，设置user.name和user.email 12$ git config --global user.name "你的GitHub用户名"$ git config --global user.email "你的GitHub注册邮箱" 生成ssh密钥： 1$ ssh-keygen -t rsa -C "你的GitHub注册邮箱" 一路回车，创建的文件windows 10系统在C:\Users\windows用户\.ssh，里面有新创建的私钥：id_rsa和公钥：id_rsa.pub。 点击GitHub用户头像–>Setting–>SSH and GPG keys–>New SSH key，将公钥 id_rsa.pub 中的内容复制到key文本框中点击保存。 测试SSH： 1$ ssh -T git@github.com 会出现确认信息，确认无误输入yes后回车。配置完成。 Hexo安装及配置创建博客文件夹 创建博客文件夹，命名为blog 1> mkdir blog 进入blog文件夹 1> cd blog 以下操作全部在blog文件夹内执行 安装Hexo1> npm install -g hexo-cli 初始化Hexo1> hexo init 安装依赖1> npm install 生成静态页1> hexo generate 启动服务1> hexo server 启动成功，可以通过浏览器地址栏输入：http://localhost:4000/ ，看到Hexo的示例页。使用Ctrl+c停止预览服务。 部署Hexo 编辑Hexo配置文件_config.yml，找到下面内容： 1234# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: 添加GitHub仓库信息： 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:/.github.io.git #github仓库地址 branch: master #github分支 安装Git插件 1> npm install hexo-deployer-git --save 部署 1> hexo deploy 部署成功，通过http://.github.io访问。 Hexo常用命令123456> hexo new #新建文章> hexo generate #生成静态页面 hexo g> hexo clean #清除生成内容> hexo server #启动服务 hexo s> hexo deploy #部署 hexo d> hexo clean && hexo g -d #清除、生成、部署 Hexo插件文章置顶安装node插件 12$ npm uninstall hexo-generator-index --save$ npm install hexo-generator-index-pin-top --save 在需要顶置的文章的Front-matter中加top: true。 显示版权信息修改主题配置文件中enable: false为enable: true。 修改站点配置文件中url:为url: http://。 12345# Declare license on postspost_copyright: enable: false license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/ 访问统计功能修改主题配置文件中busuanzi_count: 部分。 123456789101112131415161718192021# Show PV/UV of the website/page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzi/busuanzi_count: # count values only if the other configs are false # 全局开关 enable: true # custom uv span for the whole site # 页面底部显示站点的UV值 site_uv: true site_uv_header: 访客数 site_uv_footer: 人次 # custom pv span for the whole site # 页面底部显示站点的PV值 site_pv: true site_pv_header: 访问量 site_pv_footer: 次 # custom pv span for one page only # 文章页面的标题下显示该页面的PV值 page_pv: true page_pv_header: 阅读量 page_pv_footer: 次 显示文章更新时间修改主题配置文件中post_meta部分的updated_at: false为updated_at: true。 123456# Post meta display settingspost_meta: item_text: true created_at: true updated_at: false categories: tru 在需要顶置的文章的Front-matter中加updated:。 添加文章字数统计安装插件： 1$ npm i hexo-wordcount --save 修改主题配置文件中post_wordcount部分： 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true //底部是否显示“总字数”字样 wordcount: true //文章字数统计 默认false min2read: false //文章预计阅读时长（分钟） totalcount: true //网站总字数，位于底部 默认false separated_meta: true //是否将文章的字数统计信息换行显示 更多插件可以查阅官方插件页 Next安装及配置Next主题安装下载稳定版本：Next发布页面 解压出文件夹，重命名文件夹名称为next，放在blog/themes内。 Next主题配置 Hexo根目录中_config.yml为站点配置文件，主题包内_config.yml为主题配置文件。 在站点配置文件中找到theme修改值为next。 12## Themes: https://hexo.io/themes/ #主题theme: next #主题名称 默认landscape 详细配置说明：Next主题设定 相关参考 手把手教从零开始在GitHub上使用Hexo搭建博客教程(一)-附GitHub注册及配置 手把手教从零开始在GitHub上使用Hexo搭建博客教程(二)-Hexo参数设置 使用GitHub搭建Hexo静态博客 Hexo博客功能优化 Hexo官方中文文档]]></content>
      <categories>
        <category>Hexo博客</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
